{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action Recognition Project",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQxcTmy-o0Qp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Click Me { form-width: \"10%\" }\n",
        " \n",
        "%%html\n",
        "<!--    \n",
        ",_._._._._._._._._|__________________________________________________________,\n",
        "|_|_|_|_|_|_|_|_|_|_________________________________________________________/\n",
        "        \n",
        " \n",
        "Folder With All Saved Data\n",
        "https://drive.google.com/open?id=1ak2PrL1t3pQCo8VYzHXm9zuOM0Og9cjC \n",
        " \n",
        "-->\n",
        " \n",
        "<marquee style='width: 75%; color: #000000;'><h3>Enjoy :)</h3></marquee>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbGA5UHHiFCV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Geting The Dataset{ form-width: \"10%\" }\n",
        "\n",
        "# Geting The Training Dataset\n",
        "!gdown --id \"1fu93ErsAOzDf9kK2ws4I2ILcMYr2SZbF\"\n",
        "# If You Wander What Is This Magic Numbers check the link \n",
        "# https://drive.google.com/file/d/1fu93ErsAOzDf9kK2ws4I2ILcMYr2SZbF/view\n",
        "get_ipython().system_raw(\"unrar x Training_set\")\n",
        "\n",
        "# Geting The Testing Dataset\n",
        "!gdown --id \"1tfcRgZrMp8cVJeH-YY2YO0RJEe9dKMVy\"\n",
        "get_ipython().system_raw(\"unrar x Testing_set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otg_1nLTlQsM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Libraries { form-width: \"3%\" }\n",
        " \n",
        "# Helpers \n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored, cprint\n",
        "from numba import cuda\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import csv\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        " \n",
        "# Keras\n",
        "from keras.layers import Dense, Activation, Dropout, Bidirectional\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# from keras.applications import inception_v3\n",
        "# from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySHp-XSulYT0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Hyperparameter { form-width: \"3%\" }\n",
        "\n",
        "## Pathes\n",
        "# Pathes Of Training\n",
        "TRAINING_PATH_FOLDER = '/content/Training'\n",
        "TRAINING_NPY = '/content/drive/My Drive/Video Action Recognition/train.npy'\n",
        "TRAINING_LABEL_NPY = '/content/drive/My Drive/Video Action Recognition/train_label.npy'\n",
        "\n",
        "# Paths Of Testing\n",
        "TESTING_PATH_FOLDER = '/content/Testing_set'\n",
        "TESTING_NPY = '/content/drive/My Drive/Video Action Recognition/test.npy'\n",
        "TESTING_LABEL_NPY = '/content/drive/My Drive/Video Action Recognition/test_label.npy'\n",
        "\n",
        "# Path Of Hidden\n",
        "HIDDEN_NPY = '/content/drive/My Drive/Video Action Recognition/hidden.npy'\n",
        "\n",
        "# Path Of Weights\n",
        "WEIGHTS_PATH = '/content/drive/My Drive/Video Action Recognition/weights.h5'\n",
        "\n",
        "# Path Of CSV\n",
        "CSV_PATH = '/content/drive/My Drive/Video Action Recognition/submit.csv'\n",
        "CSV_SORTED_PATH = '/content/drive/My Drive/Video Action Recognition/sorted.csv'\n",
        "\n",
        "## Flags\n",
        "# True For Training False For Testing\n",
        "# MASTER_FLAG = True\n",
        "MASTER_FLAG = False\n",
        "# True For Loading False For Saving\n",
        "LOAD_SAVE = False\n",
        "# LOAD_SAVE = True\n",
        "\n",
        "# Labels In Video Names\n",
        "LABELS = [\"diving\", \"jumping\", \"shooting\", \"tennis\", \"walk\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ceeD08je0nE",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Didn't know there is Folders Preprocessing { form-width: \"3%\" }\n",
        "'''\n",
        "    So To Understand What We Did Here But Before That Let Me Show You The Structre\n",
        "    Of Training & Testing Floders\n",
        "    \n",
        "\n",
        "├── Testing_set\n",
        "│   ├── test_image (1).jpg\n",
        "│   │ \n",
        "│   └──test_image (10).mpg.jpg\n",
        "│\n",
        "├── Training\n",
        "│   ├── Basketball\n",
        "│   │   └── v_shooting_01_01\n",
        "│   └── Jumping\n",
        "│       └── v_jumping_01_03\n",
        "\n",
        "    The Sturctre Is Diffrent That Will Affect When We Reading Videos As Training Require Two\n",
        "    Loops And Testing Require One Loop To Read Videos So We Create A Folder In Testing_set\n",
        "    And Move All Videos To It\n",
        "'''\n",
        "\n",
        "!mkdir /content/Testing_set/test\n",
        "!mv /content/Testing_set/*.mpg /content/Testing_set/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00C2dVzRofrj",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Feature Extraction { form-width: \"3%\" }\n",
        "\n",
        "def we_are_equal(videos_features, average_frames_count):\n",
        "    \"\"\"   \n",
        "    Make Frames For Each Video Equal\n",
        "  \n",
        "    Parameters: \n",
        "    numpy array : All Videos Features \n",
        "    int         : Average Frames\n",
        "\n",
        "    Returns: \n",
        "    numpy array :  Numpy Arrays Each Element Is For A Video Each Video Has The Same Frame Count\n",
        "    \"\"\"\n",
        " \n",
        "    for video_index in range(len(videos_features)):\n",
        "        # Set Single video [#Frames, #Features]\n",
        "        temp_single_video = videos_features[video_index]\n",
        "        temp_frames = temp_single_video.shape[0]\n",
        "\n",
        "        if temp_frames > average_frames_count:\n",
        "            temp_single_video = temp_single_video[0:average_frames_count, :]\n",
        "            videos_features[video_index] = temp_single_video\n",
        "\n",
        "        elif temp_frames < average_frames_count:\n",
        "            temp = np.zeros(shape=(average_frames_count, temp_single_video.shape[1]))\n",
        "            temp[0:temp_frames, :] = temp_single_video\n",
        "            videos_features[video_index] = temp\n",
        "    return videos_features\n",
        "\n",
        "def get_videos_features():\n",
        "    \"\"\"   \n",
        "    Get Features Of Each Frame For Each Video\n",
        "  \n",
        "    Parameters: \n",
        "    None \n",
        "  \n",
        "    Returns: \n",
        "    List(numpy array) : A List Of Numpy Arrays Each Aarray's Sahpe [#Frames, Feature Of Each Frame]\n",
        "    \"\"\"\n",
        "\n",
        "    print('Preprocessing videos')\n",
        "\n",
        "    # This Model Responsible For Extracting Features For Each Frame\n",
        "    # VGG\n",
        "    spical_model = VGG16(include_top=False, weights='imagenet')\n",
        "    spical_model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Inception\n",
        "    # spical_model = inception_v3.InceptionV3(include_top=False, weights='imagenet')\n",
        "    # spical_model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Global Variables\n",
        "    image_size = 244\n",
        "    all_video_features = []\n",
        "    all_video_label = []\n",
        "    all_videos_frames = []\n",
        "    all_videos_id = []\n",
        "\n",
        "    skip_millseconds = 500 # 1000 = 1 second\n",
        "    # Loop Through Each Video\n",
        "    if MASTER_FLAG :\n",
        "        train_or_test_path = TRAINING_PATH_FOLDER\n",
        "    else:\n",
        "        train_or_test_path = TESTING_PATH_FOLDER\n",
        "    for folder_name in tqdm(os.listdir(train_or_test_path)):\n",
        "        for video_name in os.listdir(train_or_test_path + '/' + folder_name):\n",
        "            video_path = train_or_test_path + '/' + folder_name + '/' + video_name\n",
        "\n",
        "            # Multiply With skip_millseconds To Go To A Spacific Millisecond In A Vodeo\n",
        "            # Also We Use This Variable As Frames Count For Each Video\n",
        "            go_to_millsecond = 0 \n",
        "\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            single_vidoe_features = []\n",
        "            while True:\n",
        "\n",
        "                # CAP_PROP_POS_MSEC Get Current Time In Millisecond Set Function Change This Flag\n",
        "                cap.set(cv2.CAP_PROP_POS_MSEC, (go_to_millsecond*skip_millseconds))\n",
        "\n",
        "                # Flag Will Be False When Reaching The End Of The Video\n",
        "                flag, image = cap.read()\n",
        "                \n",
        "                if flag:\n",
        "                    # Whithout This Condition  It Will Go In Infinite Loop\n",
        "                    if(cap.get(cv2.CAP_PROP_POS_FRAMES) > cap.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
        "                        break\n",
        "\n",
        "                    # Explanation For interpolation=cv2.INTER_AREA\n",
        "                    # http://shorturl.at/bexXY\n",
        "                    img = cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                    input = img_to_array(img)\n",
        "\n",
        "                    # [224, 224] => [1, 224, 224] So We Can Feed It To The Model\n",
        "                    input = np.expand_dims(input, axis=0)\n",
        "\n",
        "                    # Explanation For preprocess_input\n",
        "                    # https://stackoverflow.com/a/47556342/8236482\n",
        "                    input = preprocess_input(input)\n",
        "\n",
        "                    single_frame_features = spical_model.predict(input).ravel()\n",
        "                    single_vidoe_features.append(single_frame_features)\n",
        "                    go_to_millsecond = go_to_millsecond + 1\n",
        "                else:\n",
        "                    break\n",
        "            all_videos_frames.append(go_to_millsecond)\n",
        "            all_video_features.append(np.array(single_vidoe_features))\n",
        "            # Get Video Label\n",
        "            if MASTER_FLAG:\n",
        "                for label in LABELS:\n",
        "                    if label in video_name:\n",
        "                        all_video_label.append(LABELS.index(label))\n",
        "            else:\n",
        "                all_videos_id.append(video_name)\n",
        "\n",
        "    # We Will Use It In The Temporal Model\n",
        "    hidden = np.array(all_video_features[0].shape[1])\n",
        "\n",
        "    # Make All Videos Have The Same Count Of Frames\n",
        "    mean = int(np.mean(np.asarray(all_videos_frames)))\n",
        "    print('---------------------------------------------------')\n",
        "    print('Avarge Frame:', mean)\n",
        "    print('---------------------------------------------------')\n",
        "    all_features = we_are_equal(all_video_features, mean)\n",
        "    all_features = np.asarray(all_features)\n",
        "\n",
        "    # Encode The Labels\n",
        "    if MASTER_FLAG:\n",
        "        all_video_label = np_utils.to_categorical(all_video_label, 5)\n",
        "        all_video_label = np.asarray(all_video_label)\n",
        "    else:\n",
        "        all_videos_id = np.asarray(all_videos_id)\n",
        "\n",
        "    # Saving \n",
        "    print('---------------------------------------------------')\n",
        "    print('Saving Training Data')\n",
        "    print('---------------------------------------------------')\n",
        "    if MASTER_FLAG:\n",
        "        np.save(TRAINING_NPY, all_features)\n",
        "        np.save(TRAINING_LABEL_NPY, all_video_label)\n",
        "    else:\n",
        "        np.save(TESTING_NPY, all_features)\n",
        "        np.save(TESTING_LABEL_NPY, all_videos_id)\n",
        "    \n",
        "    np.save(HIDDEN_NPY, hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_7hMzhBVUHY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Model Requirements { form-width: \"3%\" }\n",
        " \n",
        "def temporal_model(avg, lstm_par):\n",
        "    \"\"\"   \n",
        "    Building temporal model layers\n",
        "  \n",
        "    Parameters: \n",
        "    int : LSTM Parametar\n",
        " \n",
        "    Returns: \n",
        "Y   keras model :  The Model\n",
        "    \"\"\"\n",
        "    temporal = Sequential()\n",
        "    # memory 1\n",
        "    # Explanition for LSTM parametars\n",
        "    # https://www.youtube.com/watch?v=LZ-GS7LOyWs&t=334s\n",
        " \n",
        "    temporal.add(\n",
        "        Bidirectional(\n",
        "            LSTM(units=256, return_sequences=True),\n",
        "            input_shape=(avg, lstm_par)\n",
        "        )\n",
        "    )\n",
        "    temporal.add(LSTM(200))\n",
        " \n",
        "    \n",
        "    \n",
        "    # Normal Ending\n",
        "    temporal.add(Dropout(0.55))\n",
        "    temporal.add(Dense(5))\n",
        "    temporal.add(Activation('softmax'))\n",
        "    temporal.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return temporal\n",
        " \n",
        "def batching(data, labels):\n",
        "    \"\"\"   \n",
        "    Generate Batches\n",
        " \n",
        "    Parameters: \n",
        "    numpy array : Features Of Each Video\n",
        "    numpy array : Label Of Each Video\n",
        " \n",
        "    Returns: \n",
        "    numpy array : Segments Of Data\n",
        "    \"\"\"\n",
        "    batches_count = len(data) // 32\n",
        "    while True:\n",
        "        for index in range(0, batches_count):\n",
        "            begin_batch = 32 * index \n",
        "            end_batch = 32 * (index + 1)\n",
        "            # Explanition For Yield\n",
        "            # shorturl.at/tVW37\n",
        "            yield np.array(data[begin_batch:end_batch]), labels[begin_batch:end_batch]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X778QoHE-uhC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Free Resources { form-width: \"3%\" }\n",
        "\n",
        "# Trying To Free Colab GPU & Memory\n",
        "cuda.select_device(0)\n",
        "cuda.close()\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsXysX02iZUk",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Main { form-width: \"3%\" }\n",
        "\n",
        "split_percentage = 0.2\n",
        "start_epoch = 3\n",
        "to_epoch = 10\n",
        "print_red_on_yellow = lambda x: cprint(x, 'grey', 'on_yellow')\n",
        "\n",
        "for epoch_index in range(start_epoch, to_epoch):\n",
        "    print_red_on_yellow('---------------------------------------Epoch: {}---------------------------------------'.format(epoch_index))\n",
        "    for flag_filter in range(2):\n",
        "        if(flag_filter == 0):\n",
        "            MASTER_FLAG = True\n",
        "        else:\n",
        "            MASTER_FLAG = False\n",
        "\n",
        "        # True For Loading False For Saving\n",
        "        LOAD_SAVE = True\n",
        "\n",
        "        # Geting Or Prepare The Data\n",
        "        if MASTER_FLAG:\n",
        "            if LOAD_SAVE:\n",
        "                print('---------------------------------------------------')\n",
        "                print(colored('Loading Training Data And Train', 'green'))\n",
        "                train = np.load(TRAINING_NPY, allow_pickle=True)\n",
        "                train_label = np.load(TRAINING_LABEL_NPY, allow_pickle=True)\n",
        "\n",
        "                # Just A Single Number \n",
        "                LSTM_parametar = int(np.load(HIDDEN_NPY, allow_pickle=True))\n",
        "                avarge_frames = train[0].shape[0]\n",
        "\n",
        "                # Get The Model\n",
        "                final_model = temporal_model(avarge_frames, LSTM_parametar)\n",
        "\n",
        "                # Split The Data\n",
        "                Xtrain, Xtest, Ytrain, Ytest = train_test_split(train, train_label, test_size=split_percentage)\n",
        "\n",
        "                # Batches Count\n",
        "                b_train_count = len(Xtrain) / 32\n",
        "                b_test_count = len(Xtest) / 32\n",
        "\n",
        "                # Manully Generate Batches\n",
        "                b_train = batching(Xtrain, Ytrain)\n",
        "                b_test  = batching(Xtest, Ytest)\n",
        "\n",
        "                # Finally Training The Model\n",
        "                final_model.fit_generator(\n",
        "                    generator=b_train, steps_per_epoch=b_train_count,\n",
        "                    validation_data=b_test, validation_steps=b_test_count,\n",
        "                    epochs=epoch_index, verbose = 0\n",
        "                )\n",
        "                final_model.save_weights(WEIGHTS_PATH)\n",
        "            else:\n",
        "                print('---------------------------------------------------')\n",
        "                print(colored('Start Preprocessing Training Data And Saving', 'green'))\n",
        "                get_videos_features()\n",
        "        else:\n",
        "            if LOAD_SAVE:\n",
        "                print('---------------------------------------------------')\n",
        "                print(colored('Loading Testing Data And Predict', 'green'))\n",
        "                test = np.load(TESTING_NPY, allow_pickle=True)\n",
        "                test_label = np.load(TESTING_LABEL_NPY, allow_pickle=True)\n",
        "                LSTM_parametar = int(np.load(HIDDEN_NPY, allow_pickle=True))\n",
        "\n",
        "                avarge_frames = test[0].shape[0]\n",
        "                final_model = temporal_model(avarge_frames, LSTM_parametar)\n",
        "                final_model.load_weights(WEIGHTS_PATH)\n",
        "\n",
        "                # Videos ID's And Labels\n",
        "                videos_ids_labels = dict()\n",
        "\n",
        "                # Prepare Submition File\n",
        "                open(CSV_PATH, \"w\").close()\n",
        "                with open(CSV_PATH, 'w') as f:\n",
        "                    f.write('Video,Label\\n')\n",
        "                for test_index in range(len(test)):\n",
        "                    test_input = np.expand_dims(test[test_index], axis=0)\n",
        "                    predicted_label = np.argmax(final_model.predict(test_input)[0])\n",
        "                    with open(CSV_PATH, 'a') as f:\n",
        "                        f.write('{},{}\\n'.format(test_label[test_index], predicted_label))\n",
        "                        videos_ids_labels.update( {test_label[test_index] : predicted_label} )\n",
        "\n",
        "                # Importand This Code For Calculating The Accurcey\n",
        "                true_positive = 0\n",
        "                with open(CSV_SORTED_PATH) as csv_file:\n",
        "                    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "                    line_count = 0\n",
        "                    for row in csv_reader:\n",
        "                        if line_count == 0:\n",
        "                            line_count += 1\n",
        "                        else:\n",
        "                            if(int(videos_ids_labels[row[0]]) == int(row[1])):\n",
        "                                true_positive += 1\n",
        "\n",
        "                print('---------------------------------------------------')\n",
        "                # Some Colorful Stuff\n",
        "                final_accurcy = (true_positive/127) * 100\n",
        "                color = ''\n",
        "                if final_accurcy >= 90:\n",
        "                    color = 'green'\n",
        "                elif final_accurcy < 90 and final_accurcy >= 80:\n",
        "                    color = 'yellow'\n",
        "                else:\n",
        "                    color = 'red'\n",
        "\n",
        "                print(colored('Final Accurecy: {}'.format(final_accurcy), color))\n",
        "                print(colored('Submit CSV File', 'green'))\n",
        "                print('---------------------------------------------------')\n",
        "                \n",
        "            else:\n",
        "                print('---------------------------------------------------')\n",
        "                print(colored('Start Preprocessing Testing Data And Saving', 'green'))\n",
        "                get_videos_features()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C29TcAvAm8k",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Didn't know there is CSV Preprocessing { form-width: \"3%\" }\n",
        "# For Only One Run The Csv Sorted File Will Be Provided\n",
        "\n",
        "print('---------------------------------------------------')\n",
        "print('Start CSV Preprocessing')\n",
        "print('---------------------------------------------------')\n",
        "\n",
        "videos_labels_sorted = []\n",
        "sorted_labels = []\n",
        "\n",
        "# Extracting Data From CSV File\n",
        "with open(CSV_PATH) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            videos_labels_sorted.append(row)\n",
        "            line_count += 1\n",
        "\n",
        "# Sort The Data Into CSV File\n",
        "for index in range(128):\n",
        "    for sublist in videos_labels_sorted:\n",
        "        exploded = re.split('. |\\(|\\)', sublist[0])\n",
        "        if str(index) == exploded[2]:\n",
        "            sorted_labels.append(sublist)\n",
        "\n",
        "# Save The Data Into CSV File\n",
        "open(CSV_SORTED_PATH, \"w\").close()\n",
        "with open(CSV_SORTED_PATH, 'w') as f:\n",
        "    f.write('Video,Label\\n')\n",
        "for video_info in sorted_labels:\n",
        "    with open(CSV_SORTED_PATH, 'a') as f:\n",
        "        f.write('{},{}\\n'.format(video_info[0], video_info[1]))\n",
        "\n",
        "print('---------------------------------------------------')\n",
        "print('CSV Preprocessing End Successfully')\n",
        "print(colored('NOW YOU NEED TO MANUALLY LABEL EACH VIDEO IN SORTED CSV', 'green'))\n",
        "print('---------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JioTD7NmBe7v",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "outputId": "21c80a2f-1315-4bde-b612-b9e90e937674"
      },
      "source": [
        "#@title End Of Project { form-width: \"3%\" }\n",
        "%%html\n",
        "<marquee style='width: 75%; color:black;'><h3> Best Accurcy : 92 % </h3></marquee>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<marquee style='width: 75%; color:black;'><h3> Best Accurcy : 92 % </h3></marquee>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}